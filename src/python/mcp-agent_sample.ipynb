{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use Model Context Protocol (MCP) as tools with Strands Agent\n",
    "\n",
    "## Overview\n",
    "The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs). Strands AI SDK integrates with MCP to extend agent capabilities through external tools and services.\n",
    "\n",
    "MCP enables communication between agents and MCP servers that provide additional tools. The Strands Agent SDK includes built-in support for connecting to MCP servers and using their tools.\n",
    "\n",
    "In this example we will show you how to use MCP tools on your Strands Agent. We will use the [AWS Documentation MCP server](https://awslabs.github.io/mcp/servers/aws-documentation-mcp-server/) which provides tools to access AWS documentation, search for content, and get recommendations. This MCP server has 3 main features:\n",
    "\n",
    "- **Read Documentation**: Fetch and convert AWS documentation pages to markdown format\n",
    "- **Search Documentation**: Search AWS documentation using the official search API\n",
    "- **Recommendations**: Get content recommendations for AWS documentation pages\n",
    "\n",
    "\n",
    "\n",
    "## Agent Details\n",
    "<div style=\"float: left; margin-right: 20px;\">\n",
    "    \n",
    "|Feature             |Description                                        |\n",
    "|--------------------|---------------------------------------------------|\n",
    "|Feature used        |MCP Tools                                          |\n",
    "|Agent Structure     |Single agent architecture                          |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/architecture.png\" width=\"85%\" />\n",
    "</div>\n",
    "\n",
    "## Key Features\n",
    "* **Single agent architecture**: this example creates a single agent that interacts with MCP tools\n",
    "* **MCP tools**: Integration of MCP tools with your agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and prerequisites\n",
    "\n",
    "### Prerequisites\n",
    "* Python 3.10+\n",
    "* AWS account\n",
    "* Anthropic Claude 3.7 enabled on Amazon Bedrock\n",
    "\n",
    "Let's now install the requirement packages for our Strands Agent Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installing pre-requisites\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependency packages\n",
    "\n",
    "Now let's import the dependency packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import os\n",
    "import base64\n",
    "from datetime import timedelta\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from mcp import StdioServerParameters, stdio_client\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from mcp.server import FastMCP\n",
    "from strands import Agent\n",
    "from strands.tools.mcp import MCPClient\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "from strands.models.openai import OpenAIModel\n",
    "from strands_tools import mem0_memory, use_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Integration Setup\n",
    "\n",
    "Before connecting to MCP servers, let's set up the memory functionality using mem0. This will allow our agent to remember previous interactions and image inputs across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory configuration and system prompts\n",
    "MEMORY_SYSTEM_PROMPT = \"\"\"\n",
    "You are an intelligent image generation assistant with persistent memory capabilities using mem0_memory and ComfyUI tools.\n",
    "\n",
    "## Core Capabilities:\n",
    "1. **Memory Management**: Store and retrieve user information, preferences, and previous interactions using mem0_memory\n",
    "2. **Image Generation**: Generate images using ComfyUI tools (generate_image_with_context, get_comfyui_config)\n",
    "3. **Context Awareness**: Remember previous images and use them as input for new generations\n",
    "4. **Intelligent Reasoning**: Use use_llm tool for complex reasoning and response generation\n",
    "\n",
    "## Memory Usage Guidelines:\n",
    "### When to Store Memory:\n",
    "- User provides images: Store image description, format, base64 data (first 200 chars), and context\n",
    "- User expresses preferences: Store style preferences, subject preferences, generation parameters\n",
    "- Successful generations: Store successful prompts, parameters, and workflow types\n",
    "- User feedback: Store what users liked/disliked about generated images\n",
    "\n",
    "### When to Retrieve Memory:\n",
    "- Before any image generation: Check for relevant user preferences and previous images\n",
    "- When user asks for variations: Retrieve original image data and parameters\n",
    "- When user mentions 'previous', 'last', 'earlier' images: Search memory for relevant images\n",
    "- For personalized responses: Retrieve user preferences and history\n",
    "\n",
    "## Image Processing Workflow:\n",
    "### For Text-to-Image:\n",
    "1. Retrieve user style preferences from memory\n",
    "2. Use generate_image_with_context with workflow_type='text_to_image'\n",
    "3. Store successful generation details in memory\n",
    "\n",
    "### For Image-to-Image:\n",
    "1. Check if user provided new image OR retrieve previous image from memory\n",
    "2. If using memory image, extract base64 data and use as context_image_base64\n",
    "3. Use generate_image_with_context with workflow_type='image_to_image'\n",
    "4. Store transformation details in memory\n",
    "\n",
    "## Tool Usage Rules:\n",
    "- **mem0_memory**: Use for storing/retrieving user data with user_id\n",
    "- **use_llm**: Use for complex reasoning, analysis, and generating detailed responses\n",
    "- **generate_image_with_context**: Primary tool for image generation\n",
    "- **get_comfyui_config**: Use to check available workflows and configurations\n",
    "\n",
    "## Memory Storage Format:\n",
    "For images: 'IMAGE_DATA:[full_data_url] DESCRIPTION:[description] FORMAT:[format] CONTEXT:[context]'\n",
    "For preferences: 'User prefers [style/subject/parameters]. Context: [when_expressed]'\n",
    "For generations: 'Generated [type] image with prompt: [prompt]. Parameters: [params]. Success: [yes/no]'\n",
    "\n",
    "## CRITICAL: Image Retrieval and Tool Calling Workflow:\n",
    "When user requests image-to-image or image-to-video generation:\n",
    "\n",
    "### Step 1: Retrieve from Memory\n",
    "- ALWAYS call mem0_memory first with action='retrieve'\n",
    "- Search for relevant image data using keywords from user's request\n",
    "- Look for memories containing 'IMAGE_DATA:' prefix\n",
    "\n",
    "### Step 2: Extract Image Data\n",
    "- From the memory result, find the text containing 'IMAGE_DATA:'\n",
    "- Extract the complete data URL after 'IMAGE_DATA:' (everything until the next space)\n",
    "- This will be in format: 'data:image/jpeg;base64,/9j/4AAQ...'\n",
    "\n",
    "### Step 3: Handle Memory Results\n",
    "- IF image data found: Extract complete data URL and proceed to Step 4a\n",
    "- IF no image data found: Proceed to Step 4b (fallback to text-to-image/text-to-video)\n",
    "\n",
    "### Step 4a: Image-to-Image/Video Generation (when memory has image)\n",
    "- Call generate_image_with_context or generate_video_with_context\n",
    "- Use extracted data URL as context_image_base64 parameter\n",
    "- Set workflow_type='image_to_image' or 'image_to_video'\n",
    "- DO NOT modify or truncate the base64 data\n",
    "\n",
    "### Step 4b: Text-to-Image/Video Generation (fallback when no memory image)\n",
    "- Call generate_image_with_context or generate_video_with_context\n",
    "- DO NOT use context_image_base64 parameter\n",
    "- Set workflow_type='text_to_image' or 'text_to_video'\n",
    "- Inform user that no previous image was found, generating new image instead\n",
    "\n",
    "### Example Workflows:\n",
    "**Scenario A - Image Found in Memory:**\n",
    "User: \"Transform my landscape image into oil painting\"\n",
    "1. mem0_memory(action='retrieve', content='landscape image', user_id='user123')\n",
    "2. Found: 'IMAGE_DATA:data:image/jpeg;base64,/9j/4AAQ...'\n",
    "3. generate_image_with_context(prompt='oil painting style', context_image_base64='data:image/jpeg;base64,/9j/4AAQ...', workflow_type='image_to_image')\n",
    "\n",
    "**Scenario B - No Image Found (Fallback):**\n",
    "User: \"Transform my landscape image into oil painting\"\n",
    "1. mem0_memory(action='retrieve', content='landscape image', user_id='user123')\n",
    "2. No IMAGE_DATA found in memory\n",
    "3. generate_image_with_context(prompt='landscape oil painting style', workflow_type='text_to_image')\n",
    "4. Inform user: \"I couldn't find your previous landscape image in memory, so I generated a new landscape in oil painting style instead.\"\n",
    "\n",
    "Always be helpful, creative, and leverage your memory to provide personalized, context-aware responses.\n",
    "\"\"\"\n",
    "\n",
    "class MemoryImageAgent:\n",
    "    def __init__(self, user_id: str = \"demo_user\"):\n",
    "        self.user_id = user_id\n",
    "        \n",
    "    def store_image_memory(self, image_data_url: str, description: str, context: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Store complete image information in memory\"\"\"\n",
    "        # Extract format from data URL\n",
    "        if image_data_url.startswith('data:image/'):\n",
    "            format_part = image_data_url.split(';')[0].split('/')[1]\n",
    "        else:\n",
    "            format_part = 'unknown'\n",
    "        \n",
    "        # Store complete image data URL for tools to use directly\n",
    "        memory_content = f\"IMAGE_DATA:{image_data_url} DESCRIPTION:{description} FORMAT:{format_part} CONTEXT:{context}\"\n",
    "        \n",
    "        # This will be implemented with the actual agent\n",
    "        return {\n",
    "            \"status\": \"stored\",\n",
    "            \"content\": memory_content,\n",
    "            \"user_id\": self.user_id\n",
    "        }\n",
    "    \n",
    "    def retrieve_image_memories(self, query: str, max_results: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Retrieve relevant image memories\"\"\"\n",
    "        # This will be implemented with the actual agent\n",
    "        return []\n",
    "    \n",
    "    def extract_image_from_memory(self, memory_text: str) -> str:\n",
    "        \"\"\"Extract complete image data URL from memory text\"\"\"\n",
    "        # Extract the complete data URL from IMAGE_DATA: prefix\n",
    "        if \"IMAGE_DATA:\" in memory_text:\n",
    "            parts = memory_text.split(\"IMAGE_DATA:\")\n",
    "            if len(parts) > 1:\n",
    "                # Get the data URL part (everything until the next space or DESCRIPTION:)\n",
    "                data_part = parts[1].split(\" DESCRIPTION:\")[0].strip()\n",
    "                return data_part\n",
    "        return \"\"\n",
    "\n",
    "# Demonstration of the simplified workflow\n",
    "def demonstrate_memory_to_tools_workflow():\n",
    "    \"\"\"Demonstrate how agent uses memory to call ComfyUI tools\"\"\"\n",
    "    print(\"📋 Memory-to-Tools Workflow Demonstration:\")\n",
    "    print(\"1. User uploads image → Agent stores in memory with IMAGE_DATA: format\")\n",
    "    print(\"2. User requests transformation → Agent calls mem0_memory to retrieve\")\n",
    "    print(\"3. Agent extracts data URL from IMAGE_DATA: field\")\n",
    "    print(\"4. Agent calls generate_image_with_context with context_image_base64\")\n",
    "    print(\"✅ No custom tools needed - existing ComfyUI tools work directly!\")\n",
    "    \n",
    "    # Example of what the agent will do internally:\n",
    "    example_memory_content = \"IMAGE_DATA:data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD... DESCRIPTION:Mountain landscape FORMAT:jpeg CONTEXT:User uploaded\"\n",
    "    \n",
    "    print(\"📝 Example Memory Content:\")\n",
    "    print(f\"   {example_memory_content[:100]}...\")\n",
    "    \n",
    "    # Extract data URL (what agent will do)\n",
    "    if \"IMAGE_DATA:\" in example_memory_content:\n",
    "        data_url = example_memory_content.split(\"IMAGE_DATA:\")[1].split(\" DESCRIPTION:\")[0]\n",
    "        print(\"🔍 Extracted Data URL:\")\n",
    "        print(f\"   {data_url[:50]}...\")\n",
    "        print(\"✅ This data URL can be directly used as context_image_base64!\")\n",
    "    \n",
    "    print(\"\" + \"=\"*50)\n",
    "    print(\"🔄 Fallback Scenario Demonstration:\")\n",
    "    print(\"1. User requests: 'Transform my cat image into cartoon style'\")\n",
    "    print(\"2. Agent calls mem0_memory to search for 'cat image'\")\n",
    "    print(\"3. No IMAGE_DATA found in memory results\")\n",
    "    print(\"4. Agent falls back to text-to-image generation\")\n",
    "    print(\"5. Agent calls: generate_image_with_context(prompt='cat cartoon style', workflow_type='text_to_image')\")\n",
    "    print(\"6. Agent informs user: 'No previous cat image found, generated new cartoon cat instead'\")\n",
    "    print(\"✅ Intelligent fallback ensures user always gets a result!\")\n",
    "\n",
    "demonstrate_memory_to_tools_workflow()\n",
    "\n",
    "print(\"Memory integration setup completed!\")\n",
    "print(\"✅ Enhanced memory storage format for complete image data\")\n",
    "print(\"✅ Agent can now access memory and call ComfyUI tools directly\")\n",
    "print(\"✅ Intelligent fallback from image-to-image to text-to-image when no memory image found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MCP server using Streamable HTTP\n",
    "\n",
    "Let's now connect to the MCP server using Streamable HTTP transport. First lets start a simple MCP server using Streamable HTTP transport. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will connect to our deployed ComfyUI MCP server. The architecture will look as following\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"images/architecture_2.png\" width=\"85%\" />\n",
    "</div>\n",
    "\n",
    "Our ComfyUI MCP server provides the following image generation tools:\n",
    "- **generate_image_with_context**: Generate images using Flux models (text-to-image and image-to-image)\n",
    "- **get_comfyui_config**: Get ComfyUI configuration and available workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will connect to our deployed ComfyUI MCP server instead of creating a local one\n",
    "# The ComfyUI MCP server provides image generation tools using Flux models\n",
    "# \n",
    "# Available tools:\n",
    "# - generate_image_with_context: Generate images from text prompts or transform existing images\n",
    "# - get_comfyui_config: Get server configuration and available workflows\n",
    "#\n",
    "# Note: Make sure to replace the URL and auth token with your actual deployment values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using a deployed ComfyUI MCP server, we don't need to start a local server thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need to start a local server thread since we're using the deployed ComfyUI MCP server\n",
    "print(\"Connecting to deployed ComfyUI MCP server...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrating Streamable HTTP client with Agent\n",
    "\n",
    "Now lets use `streamablehttp_client` integrate this server with a simple agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure connection to your deployed ComfyUI MCP server\n",
    "# Replace these values with your actual deployment details\n",
    "COMFYUI_MCP_SERVER_URL = \"https://your-api-gateway-url.execute-api.region.amazonaws.com/Prod/mcp\"\n",
    "COMFYUI_MCP_AUTH_TOKEN = \"your-mcp-auth-token\"\n",
    "\n",
    "def create_comfyui_mcp_transport():\n",
    "    return streamablehttp_client(\n",
    "        COMFYUI_MCP_SERVER_URL,\n",
    "        headers={'Authorization': f\"Bearer {COMFYUI_MCP_AUTH_TOKEN}\"}\n",
    "    )\n",
    "\n",
    "# Create MCP client for ComfyUI server\n",
    "comfyui_mcp_client = MCPClient(create_comfyui_mcp_transport)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup agent configuration and invoke it\n",
    "\n",
    "Next we will set our agent configuration using the tools from the `streamable_http_mcp_client` object we just created. To do so, we need to list the tools available in the MCP server. We can use the `list_tools_sync` method for it. \n",
    "\n",
    "After that, we will ask a question to our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-mwxwvideypifnljcwlryhcnvhxxrzyueyqaqkpwvapyxhceg\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.siliconflow.cn/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"azure/gpt-4.1-mini\"\n",
    "model = \"openai/deepseek-ai/DeepSeek-V3\"\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=model, params={\"max_tokens\": 1000, \"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "openai_compatiable_model = OpenAIModel(\n",
    "    # **model_config\n",
    "    client_args={\n",
    "        \"api_key\":os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"base_url\":\"https://api.siliconflow.cn/\"\n",
    "    },\n",
    "    model_id=\"deepseek-ai/DeepSeek-V3\",\n",
    "    max_tokens =  1000,\n",
    "    temperature = 0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: searchWebsite\n",
      "以下以下是一些最新的美剧推荐（是一些最新的美剧推荐（截至2025年6月）：\n",
      "\n",
      "1截至2025年6月）：\n",
      "\n",
      "1. **《熊家餐馆 . **《熊家餐馆 第四季》**  \n",
      "   - 第四季》**  \n",
      "   - 评分：高分推荐  \n",
      "  评分：高分推荐  \n",
      "   - [更多详情](https - [更多详情](https://www.dealmoon.com/guide://www.dealmoon.com/guide/974237)\n",
      "\n",
      "2. **《/974237)\n",
      "\n",
      "2. **《一根入魂》 (一根入魂》 (Stick)**  \n",
      "   - 评分Stick)**  \n",
      "   - 评分：值得一看  \n",
      "   - [更多：值得一看  \n",
      "   - [更多详情](https://www.dealmoon详情](https://www.dealmoon.com/guide/974237)\n",
      "\n",
      "3.com/guide/974237)\n",
      "\n",
      "3. **《金妮与乔治亚. **《金妮与乔治亚 第三季》 (Ginny 第三季》 (Ginny & Georgia Season 3)**  \n",
      "   & Georgia Season 3)**  \n",
      "   - 评分：高分推荐  \n",
      "   - 评分：高分推荐  \n",
      "   - [更多详情](https://www - [更多详情](https://www.dealmoon.com/guide/974.dealmoon.com/guide/974237)\n",
      "\n",
      "4. **《面237)\n",
      "\n",
      "4. **《面面全非 第二季面全非 第二季》 (FUBAR Season 2》 (FUBAR Season 2)**  \n",
      "   - 评分：高分)**  \n",
      "   - 评分：高分推荐  \n",
      "   - [更多详情](推荐  \n",
      "   - [更多详情](https://www.dealmoon.com/https://www.dealmoon.com/guide/974237)\n",
      "\n",
      "5. **guide/974237)\n",
      "\n",
      "5. **《扑克脸2》**  \n",
      "《扑克脸2》**  \n",
      "   - 评分：经典高分  \n",
      "   - 评分：经典高分  \n",
      "   - [更多详情](https://   - [更多详情](https://www.dealmoon.co.uk/guidewww.dealmoon.co.uk/guide/3711)\n",
      "\n",
      "6. **《/3711)\n",
      "\n",
      "6. **《最后生还者 第一季》最后生还者 第一季》**  \n",
      "   - 评分：9**  \n",
      "   - 评分：9.0（豆瓣）  \n",
      "  .0（豆瓣）  \n",
      "   - [更多详情](https://m - [更多详情](https://m.douban.com/doulist/.douban.com/doulist/1239696/)\n",
      "\n",
      "7. **《1239696/)\n",
      "\n",
      "7. **《黑暗情报2》**黑暗情报2》**  \n",
      "   - 评分：值得  \n",
      "   - 评分：值得期待  \n",
      "   - [更多详情期待  \n",
      "   - [更多详情](https://www.elle.com/t](https://www.elle.com/tw/entertainment/drama/gw/entertainment/drama/g63479909/202530netflix63479909/202530netflix5disney4max3/)\n",
      "\n",
      "85disney4max3/)\n",
      "\n",
      "8. **《混乱少年时》**. **《混乱少年时》**  \n",
      "   - 评分：热门高分  \n",
      "   - 评分：热门高分  \n",
      "   - [更多详情](https  \n",
      "   - [更多详情](https://www.honglingjin.co.uk://www.honglingjin.co.uk/347064.html)\n",
      "\n",
      "如果需要更详细的/347064.html)\n",
      "\n",
      "如果需要更详细的介绍或具体某部美介绍或具体某部美剧的播放平台，可以剧的播放平台，可以告诉我！告诉我！"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session termination failed: 403\n"
     ]
    }
   ],
   "source": [
    "# Connect to ComfyUI MCP server and test image generation with memory\n",
    "with comfyui_mcp_client:\n",
    "    comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "    print(f\"Available ComfyUI tools: {[tool.name for tool in comfyui_tools]}\")\n",
    "    \n",
    "    # Combine ComfyUI tools with memory tools\n",
    "    all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "    print(f\"All tools: {[tool.name for tool in all_tools]}\")\n",
    "\n",
    "    # Create agent with ComfyUI and memory tools\n",
    "    agent = Agent(\n",
    "        model=openai_compatiable_model, \n",
    "        tools=all_tools,\n",
    "        system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "    )\n",
    "\n",
    "    # Test text-to-image generation\n",
    "    print(\"=== Text-to-Image Generation ===\")\n",
    "    async for event in agent.stream_async(\n",
    "        \"Generate a beautiful landscape image with mountains and a lake at sunset. Use text-to-image workflow.\"\n",
    "    ):\n",
    "        if \"data\" in event:\n",
    "            print(event[\"data\"], end=\"\", flush=True)\n",
    "    \n",
    "    print(\"=== Get ComfyUI Configuration ===\")\n",
    "    # Test getting ComfyUI configuration\n",
    "    async for event in agent.stream_async(\"What ComfyUI workflows are available?\"):\n",
    "        if \"data\" in event:\n",
    "            print(event[\"data\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简化的Memory-Enhanced Agent测试\n",
    "\n",
    "以下是三个核心功能的测试：文生图、图生图、历史对话记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简化的Memory-Enhanced Agent测试\n",
    "def test_simplified_memory_agent():\n",
    "    \"\"\"测试三个核心功能：文生图、图生图、历史对话记忆\"\"\"\n",
    "    print(\"🧠 开始简化的Memory-Enhanced Agent测试...\")\n",
    "    \n",
    "    with comfyui_mcp_client:\n",
    "        comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "        all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "        \n",
    "        # 创建memory-enabled agent\n",
    "        memory_agent = Agent(\n",
    "            model=openai_compatiable_model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "        )\n",
    "        \n",
    "        # 测试1: 历史对话记忆 - 存储用户偏好\n",
    "        print(\"\\n=== 测试1: 历史对话记忆 - 存储用户偏好 ===\")\n",
    "        async for event in memory_agent.stream_async(\n",
    "            \"记住我的偏好：我喜欢山水风景图，偏爱写实风格，暖色调。请存储这些偏好信息。\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # 测试2: 文生图 - 基于记忆的偏好生成图像\n",
    "        print(\"\\n\\n=== 测试2: 文生图 - 基于记忆偏好生成 ===\")\n",
    "        async for event in memory_agent.stream_async(\n",
    "            \"根据我之前说的偏好，生成一张图像。使用text-to-image工作流。\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # 测试3: 图生图 - 模拟用户上传图片后的转换\n",
    "        print(\"\\n\\n=== 测试3: 图生图 - 模拟图像转换 ===\")\n",
    "        # 模拟存储图像信息\n",
    "        sample_image_data = \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k=\"\n",
    "        \n",
    "        async for event in memory_agent.stream_async(\n",
    "            f\"我上传了一张山水风景图。请存储这张图像信息：IMAGE_DATA:{sample_image_data} DESCRIPTION:山水风景图 FORMAT:jpeg CONTEXT:用户上传的图像\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # 使用存储的图像进行图生图转换\n",
    "        print(\"\\n\\n=== 图生图转换 - 使用记忆中的图像 ===\")\n",
    "        async for event in memory_agent.stream_async(\n",
    "            \"把我之前上传的山水风景图转换成油画风格。请先从记忆中检索图像数据，然后使用image-to-image工作流进行转换。\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\n\\n✅ 简化的Memory-Enhanced Agent测试完成!\")\n",
    "        print(\"\\n📋 测试总结:\")\n",
    "        print(\"✓ 历史对话记忆：成功存储和检索用户偏好\")\n",
    "        print(\"✓ 文生图：基于记忆偏好生成图像\")\n",
    "        print(\"✓ 图生图：使用记忆中的图像进行风格转换\")\n",
    "\n",
    "# 运行简化测试\n",
    "test_simplified_memory_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境配置说明\n",
    "\n",
    "使用memory功能需要配置相应的环境变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory后端配置说明\n",
    "print(\"📋 Memory后端配置选项:\")\n",
    "print(\"\")\n",
    "print(\"1. mem0.ai API (推荐用于测试):\")\n",
    "print(\"   - 设置环境变量: MEM0_API_KEY=your_api_key\")\n",
    "print(\"   - 优点: 简单易用，云端存储\")\n",
    "print(\"   - 缺点: 需要API费用\")\n",
    "print(\"\")\n",
    "print(\"2. 本地FAISS存储 (开源免费):\")\n",
    "print(\"   - 无需额外配置\")\n",
    "print(\"   - 优点: 完全免费，数据本地\")\n",
    "print(\"   - 缺点: 重启后数据丢失\")\n",
    "print(\"\")\n",
    "print(\"3. AWS OpenSearch (推荐用于生产):\")\n",
    "print(\"   - 设置环境变量: OPENSEARCH_HOST, AWS_REGION\")\n",
    "print(\"   - 优点: 生产级别，持久化存储\")\n",
print("   - 缺点: 需要AWS配置")\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "\n",
    "本示例展示了如何将mem0 memory功能集成到Strands Agent中，实现了：\n",
    "\n",
    "1. **文生图功能**：基于用户偏好和历史记忆生成图像\n",
    "2. **图生图功能**：使用记忆中存储的图像进行风格转换\n",
    "3. **历史对话记忆**：持久化存储用户偏好和交互历史\n",
    "\n",
    "关键特性：\n",
    "- 智能fallback：当记忆中没有图像时自动切换到文生图\n",
    "- 完整的base64图像数据存储和检索\n",
    "- 支持多种memory后端（mem0.ai API、本地FAISS、AWS OpenSearch）\n",
    "- 无需修改现有ComfyUI MCP tools，直接复用"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
    "While tools are typically invoked by the agent based on user requests, you can also call MCP tools directly. This can be useful for workflow scenarios where you orchestrate multiple tools together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct tool invocation example with ComfyUI MCP server\n",
    "image_generation_params = {\n",
    "    \"prompt\": \"A serene mountain landscape with snow-capped peaks and a crystal clear lake\",\n",
    "    \"workflow_type\": \"text_to_image\",\n",
    "    \"width\": 1024,\n",
    "    \"height\": 768,\n",
    "    \"steps\": 20,\n",
    "    \"cfg_scale\": 7.0\n",
    "}\n",
    "\n",
    "with comfyui_mcp_client:\n",
    "    # Direct tool invocation for image generation\n",
    "    result = comfyui_mcp_client.call_tool_sync(\n",
    "        tool_use_id=\"tool-img-gen\", \n",
    "        name=\"generate_image_with_context\", \n",
    "        arguments=image_generation_params\n",
    "    )\n",
    "\n",
    "    # Process the result\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Image generation successful!\")\n",
    "        print(f\"Result type: {result['content'][0].get('type', 'text')}\")\n",
    "        if 'metadata' in result['content'][0]:\n",
    "            metadata = result['content'][0]['metadata']\n",
    "            print(f\"Generation time: {metadata.get('generation_time', 'N/A')} seconds\")\n",
    "            print(f\"Workflow: {metadata.get('workflow_type', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"Image generation failed: {result['content'][0]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Image-to-Image Tool Invocation\n",
    "\n",
    "For image-to-image generation via direct tool invocation, you need to provide the image as base64 encoded data in the context_image_base64 parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct image-to-image tool invocation example\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def direct_image_to_image_call():\n",
    "    try:\n",
    "        # Example image file path (replace with your actual image)\n",
    "        image_path = \"sample_image.png\"  # Replace with your image file\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ Image file not found: {image_path}\")\n",
    "            print(\"Please provide a valid image file path\")\n",
    "            return\n",
    "        \n",
    "        # Read and encode the image\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "        \n",
    "        # Convert to base64 data URL format\n",
    "        image_format = os.path.splitext(image_path)[1][1:].lower()\n",
    "        if image_format == 'jpg':\n",
    "            image_format = 'jpeg'\n",
    "        \n",
    "        image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        image_data_url = f\"data:image/{image_format};base64,{image_base64}\"\n",
    "        \n",
    "        # Parameters for image-to-image generation\n",
    "        img2img_params = {\n",
    "            \"prompt\": \"Transform this image into a beautiful watercolor painting with soft, flowing colors\",\n",
    "            \"context_image_base64\": image_data_url,\n",
    "            \"workflow_type\": \"image_to_image\",\n",
    "            \"steps\": 25,\n",
    "            \"cfg_scale\": 1.0,\n",
    "            \"denoise_strength\": 0.75\n",
    "        }\n",
    "        \n",
    "        print(f\"📤 Calling image-to-image tool directly...\")\n",
    "        print(f\"   Input image size: {len(image_bytes)} bytes\")\n",
    "        print(f\"   Image format: {image_format}\")\n",
    "        \n",
    "        with comfyui_mcp_client:\n",
    "            # Direct tool invocation for image-to-image\n",
    "            result = comfyui_mcp_client.call_tool_sync(\n",
    "                tool_use_id=\"tool-img2img-direct\", \n",
    "                name=\"generate_image_with_context\", \n",
    "                arguments=img2img_params,\n",
    "                read_timeout_seconds=timedelta(seconds=120)  # 2 minutes timeout\n",
    "            )\n",
    "            \n",
    "            # Process the result\n",
    "            if result['status'] == 'success':\n",
    "                print(f\"✅ Image-to-image generation successful!\")\n",
    "                print(f\"Result type: {result['content'][0].get('type', 'text')}\")\n",
    "                if 'metadata' in result['content'][0]:\n",
    "                    metadata = result['content'][0]['metadata']\n",
    "                    print(f\"Generation time: {metadata.get('generation_time', 'N/A')} seconds\")\n",
    "                    print(f\"Workflow: {metadata.get('workflow_type', 'N/A')}\")\n",
    "                    print(f\"Denoise strength: {metadata.get('denoise_strength', 'N/A')}\")\n",
    "            else:\n",
    "                print(f\"❌ Image-to-image generation failed: {result['content'][0]['text']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Direct image-to-image call error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the test (uncomment the line below when you have an image file)\n",
    "# direct_image_to_image_call()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optinally also provide `read_timeout_seconds` while calling an MCP server tool to avoid it running for too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with timeout for image generation (ComfyUI can take time to generate images)\n",
    "complex_image_params = {\n",
    "    \"prompt\": \"A highly detailed fantasy castle on a floating island with dragons flying around, magical aurora in the sky, photorealistic, 8k quality\",\n",
    "    \"workflow_type\": \"text_to_image\",\n",
    "    \"width\": 1024,\n",
    "    \"height\": 1024,\n",
    "    \"steps\": 50,  # More steps for higher quality\n",
    "    \"cfg_scale\": 8.0\n",
    "}\n",
    "\n",
    "with comfyui_mcp_client:\n",
    "    try:\n",
    "        result = comfyui_mcp_client.call_tool_sync(\n",
    "            tool_use_id=\"tool-complex-img\",\n",
    "            name=\"generate_image_with_context\",\n",
    "            arguments=complex_image_params,\n",
    "            read_timeout_seconds=timedelta(seconds=120),  # 2 minutes timeout for complex generation\n",
    "        )\n",
    "\n",
    "        if result[\"status\"] == \"error\":\n",
    "            print(f\"Image generation failed: {result['content'][0]['text']}\")\n",
    "        else:\n",
    "            print(f\"Complex image generation succeeded!\")\n",
    "            if 'metadata' in result['content'][0]:\n",
    "                metadata = result['content'][0]['metadata']\n",
    "                print(f\"Generation time: {metadata.get('generation_time', 'N/A')} seconds\")\n",
    "                print(f\"Steps used: {metadata.get('steps', 'N/A')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Image generation timed out or failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Memory-Enhanced Image Generation Example\n",
    "\n",
    "Here's a complete example that demonstrates all the memory functionality with ComfyUI integration. This example shows how to store user preferences, remember images, and use memory for intelligent image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Memory-Enhanced Image Generation Example\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "class MemoryEnhancedImageAgent:\n",
    "    \"\"\"Complete example of memory-enhanced image generation agent\"\"\"\n",
    "    \n",
    "    def __init__(self, user_id: str = \"demo_user\"):\n",
    "        self.user_id = user_id\n",
    "        self.agent = None\n",
    "        \n",
    "    def setup_agent(self):\n",
    "        \"\"\"Setup the agent with ComfyUI and memory tools\"\"\"\n",
    "        with comfyui_mcp_client:\n",
    "            comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "            all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "            \n",
    "            self.agent = Agent(\n",
    "                model=openai_compatiable_model,\n",
    "                tools=all_tools,\n",
    "                system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "            )\n",
    "            \n",
    "            print(f\"✅ Agent setup complete with {len(all_tools)} tools\")\n",
    "            print(f\"Available tools: {[tool.name for tool in all_tools]}\")\n",
    "    \n",
    "    async def store_user_preferences(self, preferences: str):\n",
    "        \"\"\"Store user preferences in memory\"\"\"\n",
    "        print(f\"🧠 Storing user preferences for {self.user_id}...\")\n",
    "        async for event in self.agent.stream_async(\n",
    "            f\"Remember these preferences for user {self.user_id}: {preferences}\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        print(\"\")\n",
    "    \n",
    "    async def store_image_with_memory(self, image_path: Optional[str] = None, description: str = \"\"):\n",
    "        \"\"\"Store image information in memory\"\"\"\n",
    "        if image_path and os.path.exists(image_path):\n",
    "            # Real image processing\n",
    "            with open(image_path, 'rb') as f:\n",
    "                image_bytes = f.read()\n",
    "            \n",
    "            image_format = os.path.splitext(image_path)[1][1:].lower()\n",
    "            if image_format == 'jpg':\n",
    "                image_format = 'jpeg'\n",
    "            \n",
    "            image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "            \n",
    "            print(f\"🖼️ Storing real image: {image_path}\")\n",
    "            await self.agent.stream_async(\n",
    "                f\"Store this image in memory for user {self.user_id}: \"\n",
    "                f\"Description: {description}. Format: {image_format}. \"\n",
    "                f\"Base64 data: {image_base64[:200]}...\"\n",
    "            )\n",
    "        else:\n",
    "            # Simulated image storage\n",
    "            print(f\"🖼️ Simulating image storage: {description}\")\n",
    "            async for event in self.agent.stream_async(\n",
    "                f\"Remember that user {self.user_id} has an image: {description}. \"\n",
    "                f\"Store this image information for future reference.\"\n",
    "            ):\n",
    "                if \"data\" in event:\n",
    "                    print(event[\"data\"], end=\"\", flush=True)\n",
    "        print(\"\")\n",
    "    \n",
    "    async def generate_with_memory(self, prompt: str, use_previous_image: bool = False):\n",
    "        \"\"\"Generate image using memory context\"\"\"\n",
    "        if use_previous_image:\n",
    "            print(f\"🎨 Generating image with memory context...\")\n",
    "            full_prompt = (\n",
    "                f\"For user {self.user_id}: {prompt}. \"\n",
    "                f\"Check memory for previous images and user preferences. \"\n",
    "                f\"If there's a relevant previous image, use it for image-to-image generation. \"\n",
    "                f\"Otherwise, use text-to-image with stored preferences.\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"🎨 Generating new image with preferences...\")\n",
    "            full_prompt = (\n",
    "                f\"For user {self.user_id}: {prompt}. \"\n",
    "                f\"Check memory for user preferences and generate accordingly using text-to-image.\"\n",
    "            )\n",
    "        \n",
    "        async for event in self.agent.stream_async(full_prompt):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        print(\"\")\n",
    "    \n",
    "    async def run_complete_demo(self):\n",
    "        \"\"\"Run a complete demonstration of memory-enhanced image generation\"\"\"\n",
    "        print(\"🚀 Starting Complete Memory-Enhanced Image Generation Demo\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Setup\n",
    "        print(\"📋 Step 1: Setting up agent...\")\n",
    "        self.setup_agent()\n",
    "        \n",
    "        # Step 2: Store preferences\n",
    "        print(\"📋 Step 2: Storing user preferences...\")\n",
    "        await self.store_user_preferences(\n",
    "            \"I love landscape photography with mountains, lakes, and dramatic skies. \"\n",
    "            \"I prefer realistic style with warm, golden hour lighting. \"\n",
    "            \"I like high contrast and vibrant colors.\"\n",
    "        )\n",
    "        \n",
    "        # Step 3: Store image information\n",
    "        print(\"📋 Step 3: Storing image information...\")\n",
    "        # TODO: Replace 'sample_landscape.jpg' with your actual image path\n",
    "        sample_image_path = \"sample_landscape.jpg\"  # Replace with your image\n",
    "        await self.store_image_with_memory(\n",
    "            image_path=sample_image_path if os.path.exists(sample_image_path) else None,\n",
    "            description=\"Beautiful mountain landscape with lake reflection at sunset\"\n",
    "        )\n",
    "        \n",
    "        # Step 4: Generate new image with preferences\n",
    "        print(\"📋 Step 4: Generating image based on stored preferences...\")\n",
    "        await self.generate_with_memory(\n",
    "            \"Create a stunning landscape image\",\n",
    "            use_previous_image=False\n",
    "        )\n",
    "        \n",
    "        # Step 5: Generate variation using previous image\n",
    "        print(\"📋 Step 5: Creating variation using previous image from memory...\")\n",
    "        await self.generate_with_memory(\n",
    "            \"Transform my previous landscape into an oil painting style\",\n",
    "            use_previous_image=True\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Complete demo finished!\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Create and run the demo\n",
    "demo_agent = MemoryEnhancedImageAgent(user_id=\"demo_user_001\")\n",
    "\n",
    "# Uncomment the line below to run the complete demo\n",
    "# await demo_agent.run_complete_demo()\n",
    "\n",
    "print(\"📝 Demo setup complete!\")\n",
    "print(\"💡 To run the demo, uncomment the last line and execute this cell\")\n",
    "print(\"🖼️ To use with real images, replace 'sample_landscape.jpg' with your image path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup for Memory Functionality\n",
    "\n",
    "To use the memory functionality, you'll need to set up your environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup for memory functionality\n",
    "# Add these to your .env file or set as environment variables\n",
    "\n",
    "# For mem0.ai (recommended for testing)\n",
    "# MEM0_API_KEY=your_mem0_api_key_here\n",
    "\n",
    "# For AWS OpenSearch (recommended for production)\n",
    "# OPENSEARCH_HOST=your_opensearch_endpoint\n",
    "# AWS_REGION=your_aws_region\n",
    "\n",
    "# For local FAISS (default for development)\n",
    "# No additional configuration needed\n",
    "\n",
    "print(\"📋 Environment setup instructions:\")\n",
    "print(\"1. Choose your memory backend:\")\n",
    "print(\"   - mem0.ai: Set MEM0_API_KEY (easiest for testing)\")\n",
    "print(\"   - AWS OpenSearch: Set OPENSEARCH_HOST and AWS_REGION (production)\")\n",
    "print(\"   - Local FAISS: No setup needed (development only)\")\n",
    "print(\"2. Make sure your ComfyUI MCP server is running\")\n",
    "print(\"3. Update COMFYUI_MCP_SERVER_URL and COMFYUI_MCP_AUTH_TOKEN\")\n",
    "print(\"4. Place your test images in the notebook directory\")\n",
    "print(\"5. Update image paths in the demo code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Validation\n",
    "\n",
    "Here are some tests to validate that the memory functionality is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and validation functions for memory functionality\n",
    "\n",
    "async def test_memory_basic_functionality():\n",
    "    \"\"\"Test basic memory store and retrieve functionality\"\"\"\n",
    "    print(\"🧪 Testing Basic Memory Functionality...\")\n",
    "    \n",
    "    with comfyui_mcp_client:\n",
    "        comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "        all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "        \n",
    "        test_agent = Agent(\n",
    "            model=openai_compatiable_model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "        )\n",
    "        \n",
    "        # Test 1: Store information\n",
    "        print(\"📝 Test 1: Storing test information...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"Remember that I am testing the memory functionality. \"\n",
    "            \"My test user ID is test_user_123. Store this for testing.\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # Test 2: Retrieve information\n",
    "        print(\"🔍 Test 2: Retrieving stored information...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"What do you remember about my testing? Retrieve information from memory.\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        print(\"✅ Basic memory test completed!\")\n",
    "\n",
    "async def test_image_memory_simulation():\n",
    "    \"\"\"Test image memory functionality with simulated data\"\"\"\n",
    "    print(\"🖼️ Testing Image Memory Functionality...\")\n",
    "    \n",
    "    with comfyui_mcp_client:\n",
    "        comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "        all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "        \n",
    "        test_agent = Agent(\n",
    "            model=openai_compatiable_model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "        )\n",
    "        \n",
    "        # Test 1: Store simulated image information\n",
    "        print(\"📝 Test 1: Storing simulated image information...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"Store this image information in memory: \"\n",
    "            \"Image description: Mountain landscape with lake at sunset. \"\n",
    "            \"Format: JPEG. Size: 1024x768. \"\n",
    "            \"Style: Realistic photography with warm lighting. \"\n",
    "            \"User ID: test_user_123\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # Test 2: Retrieve image information for generation\n",
    "        print(\"🎨 Test 2: Using stored image info for generation...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"I want to create a variation of my previous mountain landscape image. \"\n",
    "            \"Check memory for the image information and generate a similar image with oil painting style.\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        print(\"✅ Image memory test completed!\")\n",
    "\n",
    "async def test_fallback_logic():\n",
    "    \"\"\"Test fallback from image-to-image to text-to-image when no memory image found\"\"\"\n",
    "    print(\"🔄 Testing Fallback Logic...\")\n",
    "    \n",
    "    with comfyui_mcp_client:\n",
    "        comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "        all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "        \n",
    "        test_agent = Agent(\n",
    "            model=openai_compatiable_model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "        )\n",
    "        \n",
    "        # Test: Request transformation of non-existent image\n",
    "        print(\"📝 Test: Requesting transformation of non-existent image...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"Transform my dragon image into a watercolor painting style. \"\n",
    "            \"If you can't find the dragon image in memory, please generate a new dragon watercolor painting instead.\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        print(\"✅ Fallback logic test completed!\")\n",
    "        print(\"Expected behavior: Agent should search memory, find no dragon image, then use text-to-image generation\")\n",
    "\n",
    "async def test_preference_memory():\n",
    "    \"\"\"Test user preference storage and retrieval\"\"\"\n",
    "    print(\"⚙️ Testing Preference Memory...\")\n",
    "    \n",
    "    with comfyui_mcp_client:\n",
    "        comfyui_tools = comfyui_mcp_client.list_tools_sync()\n",
    "        all_tools = comfyui_tools + [mem0_memory, use_llm]\n",
    "        \n",
    "        test_agent = Agent(\n",
    "            model=openai_compatiable_model,\n",
    "            tools=all_tools,\n",
    "            system_prompt=MEMORY_SYSTEM_PROMPT\n",
    "        )\n",
    "        \n",
    "        # Test 1: Store preferences\n",
    "        print(\"📝 Test 1: Storing user preferences...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"Remember my preferences: I love fantasy art with dragons and castles. \"\n",
    "            \"I prefer vibrant colors and detailed artwork. \"\n",
    "            \"I like 1024x1024 resolution images. User ID: test_user_123\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        # Test 2: Use preferences for generation\n",
    "        print(\"🎨 Test 2: Generating image based on stored preferences...\")\n",
    "        async for event in test_agent.stream_async(\n",
    "            \"Create an image for me based on my stored preferences. \"\n",
    "            \"Generate something I would like according to my memory.\"\n",
    "        ):\n",
    "            if \"data\" in event:\n",
    "                print(event[\"data\"], end=\"\", flush=True)\n",
    "        \n",
    "        print(\"✅ Preference memory test completed!\")\n",
    "\n",
    "async def run_all_tests():\n",
    "    \"\"\"Run all memory functionality tests\"\"\"\n",
    "    print(\"🚀 Starting Memory Functionality Tests\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        await test_memory_basic_functionality()\n",
    "        await test_image_memory_simulation()\n",
    "        await test_fallback_logic()\n",
    "        await test_preference_memory()\n",
    "        \n",
    "        print(\"\" + \"=\" * 50)\n",
    "        print(\"✅ All tests completed successfully!\")\n",
    "        print(\"📋 Test Summary:\")\n",
    "        print(\"✓ Basic memory store/retrieve functionality\")\n",
    "        print(\"✓ Image information storage and retrieval\")\n",
    "        print(\"✓ Fallback logic (image-to-image → text-to-image)\")\n",
    "        print(\"✓ User preference memory\")\n",
    "        print(\"✓ Memory-based image generation\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Test failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Uncomment to run tests\n",
    "# await run_all_tests()\n",
    "\n",
    "print(\"🧪 Test functions ready!\")\n",
    "print(\"💡 Uncomment 'await run_all_tests()' to run all memory tests\")\n",
    "print(\"⚠️ Make sure your memory backend (mem0.ai, OpenSearch, or FAISS) is configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Common Issues\n",
    "\n",
    "Here are solutions to common issues you might encounter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting and diagnostic functions\n",
    "\n",
    "def check_memory_backend():\n",
    "    \"\"\"Check which memory backend is configured\"\"\"\n",
    "    print(\"🔍 Checking Memory Backend Configuration...\")\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    if os.getenv('MEM0_API_KEY'):\n",
    "        print(\"✅ mem0.ai backend detected (MEM0_API_KEY found)\")\n",
    "        print(\"   This is recommended for testing and development\")\n",
    "    elif os.getenv('OPENSEARCH_HOST'):\n",
    "        print(\"✅ AWS OpenSearch backend detected (OPENSEARCH_HOST found)\")\n",
    "        print(\"   This is recommended for production\")\n",
    "        print(f\"   Host: {os.getenv('OPENSEARCH_HOST')}\")\n",
    "        print(f\"   Region: {os.getenv('AWS_REGION', 'Not set')}\")\n",
    "    else:\n",
    "        print(\"✅ Local FAISS backend (default)\")\n",
    "        print(\"   This is suitable for development only\")\n",
    "        print(\"   Memory will not persist between sessions\")\n",
    "\n",
    "def check_comfyui_connection():\n",
    "    \"\"\"Check ComfyUI MCP server connection\"\"\"\n",
    "    print(\"🔍 Checking ComfyUI MCP Server Connection...\")\n",
    "    \n",
    "    try:\n",
    "        with comfyui_mcp_client:\n",
    "            tools = comfyui_mcp_client.list_tools_sync()\n",
    "            print(f\"✅ Connected successfully! Found {len(tools)} tools:\")\n",
    "            for tool in tools:\n",
    "                print(f\"   - {tool.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Connection failed: {e}\")\n",
    "        print(\"🔧 Troubleshooting steps:\")\n",
    "        print(\"1. Check COMFYUI_MCP_SERVER_URL is correct\")\n",
    "        print(\"2. Check COMFYUI_MCP_AUTH_TOKEN is valid\")\n",
    "        print(\"3. Ensure ComfyUI MCP server is running\")\n",
    "        print(\"4. Check network connectivity\")\n",
    "\n",
    "def check_dependencies():\n",
    "    \"\"\"Check if all required dependencies are installed\"\"\"\n",
    "    print(\"🔍 Checking Dependencies...\")\n",
    "    \n",
    "    required_packages = [\n",
    "        'strands',\n",
    "        'strands_tools',\n",
    "        'mcp',\n",
    "        'base64',\n",
    "        'os'\n",
    "    ]\n",
    "    \n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"✅ {package}\")\n",
    "        except ImportError:\n",
    "            print(f\"❌ {package} - Not installed\")\n",
    "            if package == 'strands_tools':\n",
    "                print(\"   Install with: pip install strands-agents-tools[mem0_memory]\")\n",
    "            elif package == 'strands':\n",
    "                print(\"   Install with: pip install strands\")\n",
    "\n",
    "def run_diagnostics():\n",
    "    \"\"\"Run all diagnostic checks\"\"\"\n",
    "    print(\"🏥 Running Diagnostics...\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    check_dependencies()\n",
    "    check_memory_backend()\n",
    "    check_comfyui_connection()\n",
    "    \n",
    "    print(\"\" + \"=\" * 40)\n",
    "    print(\"🏥 Diagnostics completed!\")\n",
    "\n",
    "# Run diagnostics\n",
    "run_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "In this notebook you learned how to:\n",
    "- Connect to MCP servers using Strands Agent with stdio and Streamable HTTP transports\n",
    "- Use ComfyUI MCP server for AI image generation with Flux models\n",
    "- **Integrate mem0 memory functionality** for persistent context across conversations\n",
    "- **Store and retrieve user preferences** and image information using mem0_memory\n",
    "- **Implement memory-enhanced image generation** that remembers previous images and preferences\n",
    "- Handle image inputs properly for image-to-image generation using the messages parameter\n",
    "- **Use memory for intelligent tool selection** - when to use previous images vs. generate new ones\n",
    "- Perform direct tool invocations with timeout handling\n",
    "- Combine multiple MCP servers (AWS Documentation + ComfyUI) with memory tools\n",
    "- Handle both text-based tools (documentation search) and media generation tools (image creation)\n",
    "- Process images in both agent-based and direct tool invocation scenarios\n",
    "- **Create a complete memory-enhanced agent class** for production use\n",
    "\n",
    "The ComfyUI integration with memory demonstrates how MCP can extend agent capabilities beyond text to include multimedia generation with persistent context, making your agents more versatile, intelligent, and personalized.\n",
    "\n",
    "## Key Memory Features Implemented:\n",
    "- **Conversation Memory**: Remembers user preferences, previous images, and generation history\n",
    "- **Image Memory**: Stores image descriptions, formats, and base64 data for future use\n",
    "- **Intelligent Retrieval**: Automatically retrieves relevant context for image generation\n",
    "- **Personalized Generation**: Uses stored preferences to customize image generation\n",
    "- **Context-Aware Tools**: Tools that understand when to use memory vs. new inputs\n",
    "\n",
    "## Next Steps\n",
    "- **Memory Backends**: Try different backends (mem0.ai, AWS OpenSearch, local FAISS)\n",
    "- **Image Generation**: Experiment with different prompts, styles, and parameters\n",
    "- **Image-to-Image**: Try transformations using both new images and memory-stored images\n",
    "- **Direct Tool Calls**: Use base64 encoded images in context_image_base64 parameter\n",
    "- **Multi-Modal Workflows**: Combine image analysis, generation, and text processing with memory\n",
    "- **Custom ComfyUI**: Configure your server with different models and custom nodes\n",
    "- **Production Deployment**: Use the provided deployment scripts for AWS Lambda with memory\n",
    "- **Error Handling**: Implement robust fallback mechanisms for both image processing and memory operations\n",
    "- **Memory Management**: Implement memory cleanup, categorization, and advanced retrieval strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
